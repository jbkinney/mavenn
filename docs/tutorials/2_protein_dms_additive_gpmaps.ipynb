{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Protein DMS modeling using additive G-P maps\n",
    "\n",
    "This tutorial covers perhaps the simplest application of MAVE-NN: the modeling of DMS data using an additive genotype-phenotype (G-P) map together with a global epistasis (GE) measurement process. The code below steps users through this process, and can be used to train models similar to the following built-in models, which are accessible using `mavenn.load_example_model()`:\n",
    "\n",
    "\n",
    "- `'amyloid_additive_ge'`\n",
    "- `'tdp43_additive_ge'`\n",
    "- `'gb1_additive_ge'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:24.191016Z",
     "start_time": "2021-12-16T00:28:22.614488Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2025.01.23 Works - JBK\n",
    "import sys; sys.path.insert(0, '/Users/jkinney/github/mavenn') # REMOVE IN FINAL VERSION\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import MAVE-NN\n",
    "import mavenn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "First we choose which dataset we wish to model, and we load it as a Pandas dataframe using `mavenn.load_example_dataset()`. We then compute the length of sequences in that dataset; we will need this quantity for defining the architecture of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:24.217141Z",
     "start_time": "2021-12-16T00:28:24.192066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 'amyloid' \n",
      "Sequence length: 42 amino acids (+ stops)\n",
      "data_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>dist</th>\n",
       "      <th>y</th>\n",
       "      <th>dy</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.387033</td>\n",
       "      <td>KAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.062247</td>\n",
       "      <td>NAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.818013</td>\n",
       "      <td>1.068137</td>\n",
       "      <td>TAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121805</td>\n",
       "      <td>0.376764</td>\n",
       "      <td>SAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.404340</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>IAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16061</th>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.151502</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVKV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16062</th>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.360708</td>\n",
       "      <td>0.370517</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVLV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16063</th>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.996816</td>\n",
       "      <td>0.346949</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16064</th>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.238403</td>\n",
       "      <td>0.429008</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16065</th>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.141457</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVVV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16066 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            set  dist         y        dy  \\\n",
       "0      training     1 -0.117352  0.387033   \n",
       "1      training     1  0.352500  0.062247   \n",
       "2      training     1 -2.818013  1.068137   \n",
       "3      training     1  0.121805  0.376764   \n",
       "4      training     1 -2.404340  0.278486   \n",
       "...         ...   ...       ...       ...   \n",
       "16061  training     2 -0.151502  0.389821   \n",
       "16062  training     2 -1.360708  0.370517   \n",
       "16063  training     2 -0.996816  0.346949   \n",
       "16064  training     2 -3.238403  0.429008   \n",
       "16065  training     2 -1.141457  0.365638   \n",
       "\n",
       "                                                x  \n",
       "0      KAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "1      NAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "2      TAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "3      SAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "4      IAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "...                                           ...  \n",
       "16061  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVKV  \n",
       "16062  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVLV  \n",
       "16063  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVMV  \n",
       "16064  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVTV  \n",
       "16065  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVVV  \n",
       "\n",
       "[16066 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose dataset\n",
    "dataset_name = 'amyloid'  # From Seuma et al., 2021\n",
    "# dataset_name = 'tdp43'    # From Bolognesi et al., 2019\n",
    "# dataset_name = 'gb1'      # From Olson et al., 2021. (Slowest)\n",
    "print(f\"Loading dataset '{dataset_name}' \")\n",
    "\n",
    "# Load datset\n",
    "data_df = mavenn.load_example_dataset(dataset_name)\n",
    "\n",
    "# Get and report sequence length\n",
    "L = len(data_df.loc[0,'x'])\n",
    "print(f'Sequence length: {L:d} amino acids (+ stops)')\n",
    "\n",
    "# Preview dataset\n",
    "print('data_df:')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the built-in function `mavenn.split_dataset()` to split our dataset into two dataframes:\n",
    "\n",
    "- `trainval_df`, which contains both the **training set** and **validation set* data.\n",
    "- `test_df`, which contains only the **test set** data.\n",
    "\n",
    "Note that `training_df`, previewed below, includes an extra column called `'validation'` that flags which sequences are reserved for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:24.229206Z",
     "start_time": "2021-12-16T00:28:24.218577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set   :   14,481 observations (  90.13%)\n",
      "Validation set :      826 observations (   5.14%)\n",
      "Test set       :      759 observations (   4.72%)\n",
      "-------------------------------------------------\n",
      "Total dataset  :   16,066 observations ( 100.00%)\n",
      "\n",
      "trainval_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>dist</th>\n",
       "      <th>y</th>\n",
       "      <th>dy</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.387033</td>\n",
       "      <td>KAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.062247</td>\n",
       "      <td>NAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.818013</td>\n",
       "      <td>1.068137</td>\n",
       "      <td>TAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121805</td>\n",
       "      <td>0.376764</td>\n",
       "      <td>SAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.404340</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>IAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15302</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.151502</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVKV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15303</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.360708</td>\n",
       "      <td>0.370517</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVLV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.996816</td>\n",
       "      <td>0.346949</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.238403</td>\n",
       "      <td>0.429008</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.141457</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVVV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15307 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       validation  dist         y        dy  \\\n",
       "0           False     1 -0.117352  0.387033   \n",
       "1           False     1  0.352500  0.062247   \n",
       "2           False     1 -2.818013  1.068137   \n",
       "3           False     1  0.121805  0.376764   \n",
       "4           False     1 -2.404340  0.278486   \n",
       "...           ...   ...       ...       ...   \n",
       "15302       False     2 -0.151502  0.389821   \n",
       "15303       False     2 -1.360708  0.370517   \n",
       "15304       False     2 -0.996816  0.346949   \n",
       "15305       False     2 -3.238403  0.429008   \n",
       "15306       False     2 -1.141457  0.365638   \n",
       "\n",
       "                                                x  \n",
       "0      KAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "1      NAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "2      TAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "3      SAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "4      IAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA  \n",
       "...                                           ...  \n",
       "15302  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVKV  \n",
       "15303  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVLV  \n",
       "15304  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVMV  \n",
       "15305  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVTV  \n",
       "15306  DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVVV  \n",
       "\n",
       "[15307 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset \n",
    "trainval_df, test_df = mavenn.split_dataset(data_df)\n",
    "\n",
    "# Preview trainval_df\n",
    "print('trainval_df:')\n",
    "trainval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the architecture of the model we wish to train . To do this, we create an instance of the `mavenn.Model` class, called `model`, using the following keyword arguments:\n",
    "\n",
    "- `L=L` specifies the sequence length.\n",
    "- `alphabet='protein*'` specifies that the alphabet our sequences are built from consists of 21 characters representing the 20 amino acids plus a stop signal (which is represented by the character `'*'`). Other possible choices for `alphabet` are `'dna'`, `'rna'`, and `'protein'`.\n",
    "- `gpmap_type='additive'` specifies that we wish to infer an additive G-P map.\n",
    "- `regression_type='GE'` specifies that our model will have a global epistasis (GE) measurement process. We choose this because our MAVE measurements are continuous real numbers.\n",
    "- `ge_noise_model_type='SkewedT'` specifies the use of a skewed-t noise model in the GE measurement process. The `'SkewedT'` noise model can accommodate asymmetric noise and is thus more flexible than the default `'Gaussian'` noise model.\n",
    "- `ge_heteroskedasticity_order=2` specifies that the noise model parameters (the three parameters of the skewed-t distribution) are each modeled using quadratic functions of the predicted measurement $\\hat{y}$. This will allow our model of experimental noise to vary with signal intensity.\n",
    "\n",
    "We then set the training data by calling `model.set_data()`. The keyword argument `'validation_flags'` is used to specify which subset of the data in `trainval_df` will be used for validation (as opposed to stochastic gradient descent).\n",
    "\n",
    "Next we train the model by calling `model.fit()`. In doing so we specify a number of hyperparameters including the learning rate, the number of epochs, the batch size, whether to use early stopping, and the early stopping patience.  We also set `verbose=False` to limit the amount of user feedback.\n",
    "\n",
    "Choosing hyperparameters is somewhat of an art, and the particular values used here were found by trial and error. In general users will have to try a number of different values for these and possibly other hyperparameters in order to find ones that work well. We recommend that users choose these hyperparameters in order to maximize the final value for `val_I_var`, the variational information of the trained model on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:39.994843Z",
     "start_time": "2021-12-16T00:28:24.230012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 15,307 observations set as training data.\n",
      "Using 5.4% for validation.\n",
      "Data shuffled.\n",
      "Time to set data: 0.27 sec.\n",
      "Training time: 95.1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = mavenn.Model(L=L,\n",
    "                     alphabet='protein*',\n",
    "                     gpmap_type='additive',   \n",
    "                     regression_type='GE',\n",
    "                     ge_noise_model_type='SkewedT',\n",
    "                     ge_heteroskedasticity_order=2)\n",
    "\n",
    "# Set training data\n",
    "model.set_data(x=trainval_df['x'],\n",
    "               y=trainval_df['y'],\n",
    "               validation_flags=trainval_df['validation'])\n",
    "\n",
    "# Train model\n",
    "model.fit(learning_rate=1e-3,\n",
    "          epochs=500,\n",
    "          batch_size=64,\n",
    "          early_stopping=True,\n",
    "          early_stopping_patience=25,\n",
    "          verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the performance of our final trained model, we compute two different metrics on test data: **variational information** and **predictive information**. Variational information quantifies the performance of the full latent phenotype model (G-P map + measurement process), whereas predictive information quantifies the performance of just the G-P map. See Tareen et al. (2021) for an expanded discussion of these quantities.\n",
    "\n",
    "Note that MAVE-NN also estimates the standard errors for these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.048823Z",
     "start_time": "2021-12-16T00:28:39.995788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute variational information on test data\n",
    "I_var, dI_var =  model.I_variational(x=test_df['x'], y=test_df['y'])\n",
    "print(f'test_I_var: {I_var:.3f} +- {dI_var:.3f} bits')\n",
    "\n",
    "# Compute predictive information on test data\n",
    "I_pred, dI_pred = model.I_predictive(x=test_df['x'], y=test_df['y'])\n",
    "print(f'test_I_pred: {I_pred:.3f} +- {dI_pred:.3f} bits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the trained model we call `model.save()`. This records our model in **two separate files**: a pickle file that defines model architecture (extension `'.pickle'`), and an H5 file that records model parameters (extension `'.h5'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.059965Z",
     "start_time": "2021-12-16T00:28:40.049653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model to file\n",
    "model_name = f'{dataset_name}_additive_ge'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We now discuss how to visualize the training history, performance, and parameters of a trained model. First we  then load our model using `mavenn.load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.113262Z",
     "start_time": "2021-12-16T00:28:40.061659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete model if it is present in memory\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Load model from file\n",
    "model = mavenn.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model.history` attribute is a dict that contains values for multiple model performance metrics as a function of training epoch, each evaluated on both the training data and the validation data. `'loss'` and `'val_loss'` record loss values, while `'I_var'` and `'val_I_var'` record the variational information values. As described in Tareen et al. (2021), these metrics are closely related: variational information is an affine transformation of the per-datum log likelihood, whereas loss is equal to negative log likelihood plus regularization terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.116769Z",
     "start_time": "2021-12-16T00:28:40.114766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show metrics recorded in model.history()\n",
    "model.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting `'I_var'` and `'val_I_var'` versus epoch can often provide insight into the model training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.190144Z",
     "start_time": "2021-12-16T00:28:40.117563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create figure and axes for plotting\n",
    "fig, ax = plt.subplots(1,1,figsize=[5,5])\n",
    "\n",
    "# Plot I_var_train, the variational information on training data as a function of epoch\n",
    "ax.plot(model.history['I_var'], \n",
    "        label=r'I_var_train')\n",
    "\n",
    "# Plot I_var_val, the variational information on validation data as a function of epoch\n",
    "ax.plot(model.history['val_I_var'], \n",
    "        label=r'val_I_var')\n",
    "\n",
    "# Show I_var_test, the variational information of the final model on test data\n",
    "ax.axhline(I_var, color='C2', linestyle=':', \n",
    "           label=r'test_I_var')\n",
    "\n",
    "# Show I_pred_test, the predictive information of the final model on test data\n",
    "ax.axhline(I_pred, color='C3', linestyle=':', \n",
    "           label=r'test_I_pred')\n",
    "\n",
    "# Style plot\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('bits')\n",
    "ax.set_title('Training history: variational information')\n",
    "ax.set_ylim([0, 1.2*I_pred])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can also plot '`loss`' and '`var_loss`' if they like, though the absolute values these quantities are be more difficult to interpret than `'I_var'` and `'val_I_var'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.245798Z",
     "start_time": "2021-12-16T00:28:40.190985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create figure and axes for plotting\n",
    "fig, ax = plt.subplots(1,1,figsize=[5,5])\n",
    "\n",
    "# Plot loss_train, the loss computed on training data as a function of epoch\n",
    "ax.plot(model.history['loss'], \n",
    "        label=r'loss_train')\n",
    "\n",
    "# Plot loss_val, the loss computed on validation data as a function of epoch\n",
    "ax.plot(model.history['val_loss'], \n",
    "        label=r'val_I_var')\n",
    "\n",
    "# Style plot\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_title('Training history: loss')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to consider more traditional metrics of model performance. In the context of GE models, a natural choice is the squared Pearson correlation, $R^2$, between measurements $y$ and model predictions $\\hat{y}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.422767Z",
     "start_time": "2021-12-16T00:28:40.246599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create figure and axes for plotting\n",
    "fig, ax = plt.subplots(1,1,figsize=[5,5])\n",
    "\n",
    "# Get test data y values\n",
    "y_test = test_df['y']\n",
    "\n",
    "# Compute yhat on test data\n",
    "yhat_test = model.x_to_yhat(test_df['x'])\n",
    "\n",
    "# Compute R^2 between yhat_test and y_test\n",
    "Rsq = np.corrcoef(yhat_test.ravel(), test_df['y'])[0, 1]**2\n",
    "\n",
    "# Plot y_test vs. yhat_test\n",
    "ax.scatter(yhat_test, y_test, color='C0', s=10, alpha=.3, \n",
    "           label='test data')\n",
    "\n",
    "# Style plot\n",
    "xlim = [min(yhat_test), max(yhat_test)]\n",
    "ax.plot(xlim, xlim, '--', color='k', label='diagonal', zorder=100)\n",
    "ax.set_xlabel('model prediction ($\\hat{y}$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title(f'Standard metric of model performance:\\n$R^2$={Rsq:.3}');\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize the GE measurement process inferred as part of our latent phenotype model. Recall from Tareen et al. (2021) that the measurement process consists of \n",
    "  \n",
    "- A nonlinearity $\\hat{y} = g(\\phi)$ that deterministically maps the latent phenotype $\\phi$ to a prediction $\\hat{y}$.\n",
    "- A noise model $p(y|\\hat{y})$ that stochastically maps predictions $\\hat{y}$ to measurements $y$.\n",
    "\n",
    "We can conveniently visualize both of these quantities in a single \"global epistatsis plot\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.508909Z",
     "start_time": "2021-12-16T00:28:40.423560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create figure and axes for plotting\n",
    "fig, ax = plt.subplots(1,1,figsize=[5,5])\n",
    "\n",
    "# Get test data y values\n",
    "y_test = test_df['y']\n",
    "\n",
    "# Compute φ on test data\n",
    "phi_test = model.x_to_phi(test_df['x'])\n",
    "\n",
    "## Set phi lims and create a grid in phi space\n",
    "phi_lim = [min(phi_test)-.5, max(phi_test)+.5]\n",
    "phi_grid = np.linspace(phi_lim[0], phi_lim[1], 1000)\n",
    "\n",
    "# Compute yhat each phi gridpoint\n",
    "yhat_grid = model.phi_to_yhat(phi_grid)\n",
    "\n",
    "# Compute 95% CI for each yhat\n",
    "q = [0.025, 0.975]\n",
    "yqs_grid = model.yhat_to_yq(yhat_grid, q=q)\n",
    "\n",
    "\n",
    "# Plote 95% confidence interval\n",
    "ax.fill_between(phi_grid, yqs_grid[:, 0], yqs_grid[:, 1],\n",
    "               alpha=0.2, color='C1', lw=0, label='95% CI')\n",
    "\n",
    "# Plot GE nonlinearity\n",
    "ax.plot(phi_grid, yhat_grid, \n",
    "        linewidth=3, color='C1', label='nonlinearity')\n",
    "\n",
    "# Plot scatter of φ and y values,\n",
    "ax.scatter(phi_test, y_test,\n",
    "           color='C0', s=10, alpha=.3, label='test data',\n",
    "           zorder=+100, rasterized=True)\n",
    "\n",
    "# Style plot\n",
    "ax.set_xlim(phi_lim)\n",
    "ax.set_xlabel('latent phenotype ($\\phi$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title('GE measurement process')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the values of our model's G-P map parameters, we use the method `model.get_theta()`. This returns a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.528036Z",
     "start_time": "2021-12-16T00:28:40.509757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve G-P map parameter dict and view dict keys\n",
    "theta_dict = model.get_theta(gauge='consensus')\n",
    "theta_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to appreciate that G-P maps usually have many non-identifiable directions in parameter space. These are called **gauge freedoms**.  Interpreting the values of model parameters requires that we first \"pin down\" these gauge freedoms by using a clearly specified convention. Specifying `gauge='consensus'` in `model.get_theta()` accomplishes this fixing all the $\\theta_{l:c}$ parameters that contribute to the consensus sequence to zero. This convention allows all the other $\\theta_{l:c}$ parameters in the additive model to be interpreted as single-mutation effects, $\\Delta \\phi$, away from the consensus sequence.\n",
    "\n",
    "Finally, we use `mavenn.heatmap()` to visualize these additive parameters. This function takes a number of keyword arguments, which we summarize here. More information can be found in this function's docstring. \n",
    "\n",
    "- `ax=ax`: specifies the axes on which to draw both the heatmap and the colorbar. \n",
    "- `values=theta_dict['theta_lc']`: specifies the additive parameters in the form of a `np.array` of size `L`x`C`, where `C` is the alphabet size.\n",
    "- `alphabet=theta_dict['alphabet']`: provides a list of characters corresponding to the columns of `values`\n",
    "- `seq=model.x_stats['consensus_seq']`: causes `mavenn.heatmap()` to highlight the characters of a specific sequence of interest. In our case this is the consensus sequence, the additive parameters for which are all fixed to zero.\n",
    "- `seq_kwargs={'c':'gray', 's':25}`: provides a keyword dictionary to pass to `ax.scatter()`; this specifies how the characters of the sequence of interest are to be graphically indicated. \n",
    "- `cmap='coolwarm'`: specifies the colormap used to represent the values of the additive parameters.\n",
    "- `cbar=True`: specifies that a colorbar be drawn.\n",
    "- `cmap_size='2%'`: specifies the width of the colorbar relative to the enclosing ax object.\n",
    "- `cmap_pad=.3`: specifies the spacing between the heatmap and the colorbar.\n",
    "- `ccenter=0`: centers the colormap at zero. \n",
    "\n",
    "This function returns two objects: \n",
    "- `heatmap_ax` is the axes object on which the heatmap is drawn.\n",
    "- `cb` is the colorbar object; it's corresponding axes is given by `cb.ax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T00:28:40.643536Z",
     "start_time": "2021-12-16T00:28:40.529022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,5))\n",
    "\n",
    "# Draw heatmap\n",
    "heatmap_ax, cb = mavenn.heatmap(ax=ax,\n",
    "                                values=theta_dict['theta_lc'],\n",
    "                                alphabet=theta_dict['alphabet'],\n",
    "                                seq=model.x_stats['consensus_seq'],\n",
    "                                seq_kwargs={'c':'gray', 's':25},\n",
    "                                cmap='coolwarm',\n",
    "                                cbar=True,\n",
    "                                cmap_size='2%',\n",
    "                                cmap_pad=.3,\n",
    "                                ccenter=0)\n",
    "# Style heatmap (can be different between two dataset)\n",
    "#heatmap_ax.set_xticks()\n",
    "heatmap_ax.tick_params(axis='y', which='major', pad=10)\n",
    "heatmap_ax.set_xlabel('position ($l$)')\n",
    "heatmap_ax.set_ylabel('amino acid ($c$)')\n",
    "heatmap_ax.set_title(f'Additive parameters: {model_name}')\n",
    "\n",
    "# Style colorbar\n",
    "cb.outline.set_visible(False)\n",
    "cb.ax.tick_params(direction='in', size=20, color='white')\n",
    "cb.set_label('mutational effect ($\\Delta \\phi$)', labelpad=5, rotation=-90, ha='center', va='center')\n",
    "\n",
    "# Adjust figure and show\n",
    "fig.tight_layout(w_pad=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many of the squares in the heatmap are white. These correspond to additive parameters whose values are `NaN`. MAVE-NN sets the values of a feature effect to `NaN` when no variant in the training set exhibits that feature. Such `NaN` parameters are common as DMS libraries often do not contain a comprehensive set of single-amino-acid mutations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Bolognesi B, Faure AJ, Seuma M, Schmiedel JM, Tartaglia GG, Lehner B. The mutational landscape of a prion-like domain. Nat Commun 10:4162 (2019).\n",
    "\n",
    "2. Olson CA, Wu NC, Sun R. A comprehensive biophysical description of pairwise epistasis throughout an entire protein domain. Curr Biol 24:2643–2651 (2014).\n",
    "\n",
    "3. Seuma M, Faure A, Badia M, Lehner B, Bolognesi B. The genetic landscape for amyloid beta fibril nucleation accurately discriminates familial Alzheimer’s disease mutations. eLife 10:e63364 (2021).\n",
    "\n",
    "4. Tareen A, Kooskhbaghi M, Posfai A, Ireland WT, McCandlish DM, Kinney JB. MAVE-NN: learning genotype-phenotype maps from multiplex assays of variant effect. bioRxiv doi:10.1101/2020.07.14.201475 (2020)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
