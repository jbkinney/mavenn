{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#input_data_ordered_raw =  pd.read_csv('rnap_scanned_over_ecoli_genome200k.csv')\n",
    "input_data_ordered_raw = pd.read_csv('../GB1.csv')\n",
    "#sequences = input_data_ordered_raw['seq'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VDGV</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADGV</td>\n",
       "      <td>-1.062518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDGV</td>\n",
       "      <td>-1.576334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDGV</td>\n",
       "      <td>-1.294319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDGV</td>\n",
       "      <td>-2.779853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq       val\n",
       "0  VDGV  0.000000\n",
       "1  ADGV -1.062518\n",
       "2  CDGV -1.576334\n",
       "3  DDGV -1.294319\n",
       "4  EDGV -2.779853"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_ordered_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = input_data_ordered_raw['seq'][0:20000]\n",
    "val = input_data_ordered_raw['val'][0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEoJJREFUeJzt3X+s3fdd3/Hni6RpRyl1mxgr8o/d\nIgyj6kSaXbVBIAb1ipoUxZEoVrpBncyaJ5aibUVbPSbxc38kmkaXaijgNR0Ogjah0MWiGaxyW1Wb\n5qxuU0KbruM2S7C9JHZD4g2iAoE3f5yPw4nxzf2ee8+9x+dznw/p6Hy/n+/nnPP5+F6/zud8vp/z\nvakqJEn9+rpZN0CStL4MeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnLp91AwCu\nuuqqWlhYmHUzJGmufPazn/1qVW1dqd4lEfQLCwucOHFi1s2QpLmS5PEh9Zy6kaTOGfSS1DmDXpI6\nZ9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzl0S34zV/Fs49LEXth+7/e0zbImkCzmil6TOGfSS\n1DmDXpI6Z9BLUucMeknqnEEvSZ1zeaUm4jJKaf6sGPRJvg24d6zom4GfBO5p5QvAY8C+qnomSYA7\ngRuA54Bbqupz0222NtJ4uEuaPytO3VTVl6vqmqq6Bvg7jML7o8Ah4FhV7QaOtX2A64Hd7XYQuGs9\nGi5JGmbSOfo9wFeq6nFgL3CklR8Bbmrbe4F7auQ4sCXJ1VNprSRpYpMG/c3Ah9r2tqp6om0/CWxr\n29uBk2OPOdXKXiTJwSQnkpw4e/bshM2QJA01OOiTXAHcCPz6hceqqoCa5IWr6nBVLVbV4tatWyd5\nqCRpApOM6K8HPldVT7X9p85PybT7M638NLBz7HE7WpkkaQYmCfp38lfTNgBHgf1tez9w/1j5uzJy\nHXBubIpHkrTBBq2jT/JK4K3APx4rvh24L8kB4HFgXyt/gNHSyiVGK3RunVprJUkTGxT0VfXHwJUX\nlD3NaBXOhXULuG0qrZMkrZmXQJCkzhn0ktQ5g16SOmfQS1LnDHpJ6pyXKdaqeVVLaT44opekzhn0\nktQ5p240df4VKunS4ohekjrniF7rytG9NHuO6CWpcwa9JHXOqRttGKdxpNlwRC9JnTPoJalzBr0k\ndc6gl6TOGfSS1Lmhfxx8C/AB4A1AAf8Q+DJwL7AAPAbsq6pnkgS4k9EfCH8OuKWqPjf1lqsbrsaR\n1tfQ5ZV3Ar9dVe9IcgXw9cBPAMeq6vYkh4BDwHuB64Hd7fZm4K52L73ASxxLG2fFqZskrwa+B7gb\noKr+tKqeBfYCR1q1I8BNbXsvcE+NHAe2JLl66i2XJA0yZI7+dcBZ4D8leSjJB5K8EthWVU+0Ok8C\n29r2duDk2ONPtbIXSXIwyYkkJ86ePbv6HkiSXtKQoL8cuBa4q6reCPwxo2maF1RVMZq7H6yqDlfV\nYlUtbt26dZKHSpImMCToTwGnqurBtv8RRsH/1PkpmXZ/ph0/Dewce/yOViZJmoEVg76qngROJvm2\nVrQHeAQ4CuxvZfuB+9v2UeBdGbkOODc2xSNJ2mBDV938GPCrbcXNo8CtjN4k7ktyAHgc2NfqPsBo\naeUSo+WVt061xZKkiQwK+qr6PLB4kUN7LlK3gNvW2C7NmMsfpX74zVhJ6pxBL0mdM+glqXMGvSR1\nzqCXpM4Z9JLUOYNekjpn0EtS5wx6Serc0EsgSDPlX6GSVs8RvSR1zqCXpM4Z9JLUOYNekjrnyVhd\nUjzpKk2fI3pJ6pxBL0mdM+glqXMGvSR1blDQJ3ksye8l+XySE63stUk+nuT32/1rWnmSvD/JUpKH\nk1y7nh2QJL20SUb031dV11TV+T8Sfgg4VlW7gWNtH+B6YHe7HQTumlZjJUmTW8vUzV7gSNs+Atw0\nVn5PjRwHtiS5eg2vI0lag6Hr6Av4r0kK+KWqOgxsq6on2vEngW1teztwcuyxp1rZE2NlJDnIaMTP\nrl27Vtd6dW18Tb2k1Rsa9N9dVaeTfBPw8ST/a/xgVVV7ExisvVkcBlhcXJzosZKk4QZN3VTV6XZ/\nBvgo8CbgqfNTMu3+TKt+Gtg59vAdrUySNAMrBn2SVyZ51flt4PuBLwBHgf2t2n7g/rZ9FHhXW31z\nHXBubIpHkrTBhkzdbAM+muR8/V+rqt9O8hngviQHgMeBfa3+A8ANwBLwHHDr1FutqXM+XOrXikFf\nVY8C33GR8qeBPRcpL+C2qbROkrRmXr1Sc82rXUor8xIIktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+gl\nqXMGvSR1zqCXpM4Z9JLUOb8Zu4l5fRtpc3BEL0mdM+glqXNO3WjuOOUkTcYRvSR1zqCXpM4Z9JLU\nOefo1Q3/CIl0cY7oJalzg4M+yWVJHkryW23/dUkeTLKU5N4kV7Tyl7f9pXZ8YX2aLkkaYpIR/T8F\nvjS2fwfwvqr6FuAZ4EArPwA808rf1+pJkmZkUNAn2QG8HfhA2w/wFuAjrcoR4Ka2vbft047vafUl\nSTMw9GTsvwf+JfCqtn8l8GxVPd/2TwHb2/Z24CRAVT2f5Fyr/9XxJ0xyEDgIsGvXrtW2XxPyy0bS\n5rPiiD7JDwBnquqz03zhqjpcVYtVtbh169ZpPrUkacyQEf13ATcmuQF4BfCNwJ3AliSXt1H9DuB0\nq38a2AmcSnI58Grg6am3XJI0yIoj+qr6V1W1o6oWgJuBT1TVPwA+CbyjVdsP3N+2j7Z92vFPVFVN\ntdWSpMHWso7+vcB7kiwxmoO/u5XfDVzZyt8DHFpbEyVJazHRN2Or6lPAp9r2o8CbLlLna8APTaFt\nkqQp8JuxktQ5g16SOmfQS1LnDHpJ6pyXKVaXvGSx9Fcc0UtS5wx6SeqcQS9JnTPoJalzBr0kdc6g\nl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHVuxaBP8ook/zPJ7yb5YpKfaeWvS/Jg\nkqUk9ya5opW/vO0vteML69sFSdJLGTKi/xPgLVX1HcA1wNuSXAfcAbyvqr4FeAY40OofAJ5p5e9r\n9aSZWTj0sRdu0ma04vXoq6qAP2q7L2u3At4C/P1WfgT4aeAuYG/bBvgI8B+SpD2PZsCAkza3QXP0\nSS5L8nngDPBx4CvAs1X1fKtyCtjetrcDJwHa8XPAldNstCRpuEFBX1V/XlXXADuANwF/a60vnORg\nkhNJTpw9e3atTydJWsZEq26q6lngk8B3AluSnJ/62QGcbtungZ0A7firgacv8lyHq2qxqha3bt26\nyuZLklYyZNXN1iRb2vbfAN4KfIlR4L+jVdsP3N+2j7Z92vFPOD8vSbMz5I+DXw0cSXIZozeG+6rq\nt5I8Anw4yb8BHgLubvXvBn4lyRLwh8DN69BuSdJAQ1bdPAy88SLljzKar7+w/GvAD02ldZKkNfOb\nsZLUOYNekjpn0EtS5wx6SeqcQS9JnRuyvFLq0vg1gB67/e0zbIm0vhzRS1LnDHpJ6pxTN9pUvGSz\nNiNH9JLUOUf0nXLkunqepFVvHNFLUucMeknqnFM3Ek51qW+O6CWpc47opZdw4Ujfk7OaR47oJalz\njuilVXIZpuaFI3pJ6tyKI/okO4F7gG1AAYer6s4krwXuBRaAx4B9VfVMkgB3AjcAzwG3VNXn1qf5\n0sZydY7m0ZAR/fPAj1fV64HrgNuSvB44BByrqt3AsbYPcD2wu90OAndNvdWSpMFWDPqqeuL8iLyq\n/j/wJWA7sBc40qodAW5q23uBe2rkOLAlydVTb7kkaZCJ5uiTLABvBB4EtlXVE+3Qk4ymdmD0JnBy\n7GGnWpkkaQYGr7pJ8g3AbwD/rKr+32gqfqSqKklN8sJJDjKa2mHXrl2TPFTLcP5Y0sUMGtEneRmj\nkP/VqvrNVvzU+SmZdn+mlZ8Gdo49fEcre5GqOlxVi1W1uHXr1tW2X5K0giGrbgLcDXypqn5+7NBR\nYD9we7u/f6z83Uk+DLwZODc2xSN1z/X1utQMmbr5LuBHgN9L8vlW9hOMAv6+JAeAx4F97dgDjJZW\nLjFaXnnrVFssSZrIikFfVf8NyDKH91ykfgG3rbFdkqQp8ZuxktQ5g16SOmfQS1LnvHqlNAV+h0GX\nMkf0ktQ5g16SOmfQS1LnnKOfc84NS1qJQS+to+XeiL00gjaSQS/NwLy8AUzzuj1eA2h2DHppE1ku\nbA3hvhn00hwwiLUWBr2kQZzGmV8G/RxypU2/NvJnu9xrDWnDS9VZbkpIs2PQS5orfhqYnEE/JxwZ\naSUGoJZj0EtzZtKplUs99OeprfPKoJc656dBGfSSLhnz8kWyebPiRc2SfDDJmSRfGCt7bZKPJ/n9\ndv+aVp4k70+ylOThJNeuZ+MlSSsbcvXKXwbedkHZIeBYVe0GjrV9gOuB3e12ELhrOs2UpL9u4dDH\nXrhpeStO3VTVp5MsXFC8F/jetn0E+BTw3lZ+T1UVcDzJliRXV9UT02qwpM1n0iD3BO+LrXaOfttY\neD8JbGvb24GTY/VOtTKDXtokHF1fetZ8MraqKklN+rgkBxlN77Br1661NkPSJucbzPJWG/RPnZ+S\nSXI1cKaVnwZ2jtXb0cr+mqo6DBwGWFxcnPiNQpImtVmndFYb9EeB/cDt7f7+sfJ3J/kw8GbgnPPz\nq+cIRVo7/x8NCPokH2J04vWqJKeAn2IU8PclOQA8Duxr1R8AbgCWgOeAW9ehzZKkCQxZdfPOZQ7t\nuUjdAm5ba6Mkab1tpmmcIevoJUlzzKCXpM55rZtLjCeOpI3X+zSOI3pJ6pwjeklaRi8jfUf0ktQ5\nR/SSNKbH82QG/SWgx18sSZcOp24kqXOO6CVpgHk+MWvQbyCnaCTNgkEvSROat9G9Qb/OHMVLmjWD\nfh0Y7pIuJQa9JE3JhYO8S2Vax6CXpDWYh0/wrqOXpM45ol+DeXgnlyRH9JLUuXUZ0Sd5G3AncBnw\ngaq6fT1eZxYcxUuaN1MP+iSXAb8AvBU4BXwmydGqemTar7VRDHdJq7Fcdmz0apz1GNG/CViqqkcB\nknwY2AvMVdAb7pJ6sR5Bvx04ObZ/CnjzOrwOMH9fRZakjc6tma26SXIQONh2/yjJl1f5VFcBXwXI\nHdNo2Vx4oc+biH3eHDZdn3PHmvr8N4dUWo+gPw3sHNvf0cpepKoOA4fX+mJJTlTV4lqfZ57Y583B\nPm8OG9Hn9Vhe+Rlgd5LXJbkCuBk4ug6vI0kaYOoj+qp6Psm7gd9htLzyg1X1xWm/jiRpmHWZo6+q\nB4AH1uO5L2LN0z9zyD5vDvZ5c1j3Pqeq1vs1JEkz5CUQJKlzcxP0Sd6W5MtJlpIcusjxlye5tx1/\nMMnCxrdyugb0+T1JHknycJJjSQYttbqUrdTnsXo/mKSSzP0KjSF9TrKv/ay/mOTXNrqN0zbgd3tX\nkk8meaj9ft8wi3ZOS5IPJjmT5AvLHE+S97d/j4eTXDvVBlTVJX9jdFL3K8A3A1cAvwu8/oI6/wT4\nxbZ9M3DvrNu9AX3+PuDr2/aPboY+t3qvAj4NHAcWZ93uDfg57wYeAl7T9r9p1u3egD4fBn60bb8e\neGzW7V5jn78HuBb4wjLHbwD+CxDgOuDBab7+vIzoX7isQlX9KXD+sgrj9gJH2vZHgD1JsoFtnLYV\n+1xVn6yq59rucUbfWZhnQ37OAD8H3AF8bSMbt06G9PkfAb9QVc8AVNWZDW7jtA3pcwHf2LZfDfzf\nDWzf1FXVp4E/fIkqe4F7auQ4sCXJ1dN6/XkJ+otdVmH7cnWq6nngHHDlhrRufQzp87gDjEYE82zF\nPrePtDurqpeLEQ35OX8r8K1J/nuS4+3qsPNsSJ9/GvjhJKcYreD7sY1p2sxM+v99Iv7hkQ4k+WFg\nEfi7s27LekrydcDPA7fMuCkb7XJG0zffy+hT26eT/O2qenamrVpf7wR+uar+XZLvBH4lyRuq6i9m\n3bB5NC8j+iGXVXihTpLLGX3ce3pDWrc+Bl1KIsnfA/41cGNV/ckGtW29rNTnVwFvAD6V5DFGc5lH\n5/yE7JCf8yngaFX9WVX9H+B/Mwr+eTWkzweA+wCq6n8Ar2B0HZxeDfr/vlrzEvRDLqtwFNjftt8B\nfKLaWY45tWKfk7wR+CVGIT/v87awQp+r6lxVXVVVC1W1wOi8xI1VdWI2zZ2KIb/b/5nRaJ4kVzGa\nynl0Ixs5ZUP6/AfAHoAk384o6M9uaCs31lHgXW31zXXAuap6YlpPPhdTN7XMZRWS/CxwoqqOAncz\n+ni3xOikx82za/HaDezzvwW+Afj1dt75D6rqxpk1eo0G9rkrA/v8O8D3J3kE+HPgX1TV3H5aHdjn\nHwf+Y5J/zujE7C3zPHBL8iFGb9ZXtfMOPwW8DKCqfpHReYgbgCXgOeDWqb7+HP/bSZIGmJepG0nS\nKhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR17i8BawZlrKioMYsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_norm = (val-min(val))/(max(val)-min(val))\n",
    "plt.hist(val_norm,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 300\n",
    "t_max = 15\n",
    "t_bg = 0.01\n",
    "\n",
    "size_of_data = 10000\n",
    "#size_of_data = len(sequences)\n",
    "\n",
    "input_data_ordered_raw_copy = input_data_ordered_raw[0:size_of_data].copy()\n",
    "\n",
    "#temp = np.exp(-(np.array(input_data_ordered_raw['val'][0:size_of_data]))/T)/(1+np.exp(-(np.array(input_data_ordered_raw['val'][0:size_of_data]))/T))\n",
    "#plt.hist(t_max*temp+t_bg,bins=100)\n",
    "#plt.show()\n",
    "#np.array(input_data_ordered_raw['val'][0:100000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add transcription column to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_data_ordered_raw_copy['t'] = t_max*temp+t_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VDGV</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADGV</td>\n",
       "      <td>-1.062518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDGV</td>\n",
       "      <td>-1.576334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDGV</td>\n",
       "      <td>-1.294319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDGV</td>\n",
       "      <td>-2.779853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq       val\n",
       "0  VDGV  0.000000\n",
       "1  ADGV -1.062518\n",
       "2  CDGV -1.576334\n",
       "3  DDGV -1.294319\n",
       "4  EDGV -2.779853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_ordered_raw_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw read counts according to poission distribution and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VDGV</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADGV</td>\n",
       "      <td>-1.062518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDGV</td>\n",
       "      <td>-1.576334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDGV</td>\n",
       "      <td>-1.294319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDGV</td>\n",
       "      <td>-2.779853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FDGV</td>\n",
       "      <td>-1.126139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDGV</td>\n",
       "      <td>-3.004024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HDGV</td>\n",
       "      <td>-3.306464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IDGV</td>\n",
       "      <td>-0.012906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KDGV</td>\n",
       "      <td>-3.372794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq       val\n",
       "0  VDGV  0.000000\n",
       "1  ADGV -1.062518\n",
       "2  CDGV -1.576334\n",
       "3  DDGV -1.294319\n",
       "4  EDGV -2.779853\n",
       "5  FDGV -1.126139\n",
       "6  GDGV -3.004024\n",
       "7  HDGV -3.306464\n",
       "8  IDGV -0.012906\n",
       "9  KDGV -3.372794"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_ordered_raw_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(input_data_ordered_raw_copy['seq'],input_data_ordered_raw_copy['t_norm'],test_size=0.2,random_state=4)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(input_data_ordered_raw_copy['seq'],input_data_ordered_raw_copy['C'],test_size=0.2)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(input_data_ordered_raw_copy['seq'],input_data_ordered_raw_copy['val_norm'],test_size=0.2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences,val_norm,test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train,bins=100,color='r',density=True,alpha=0.5)\n",
    "plt.hist(y_test,bins=100,color='b',density=True,alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode the data ... this takes a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_x_train = []\n",
    "temp_x_test = []\n",
    "\n",
    "for reshape_index in range(len(x_train)):\n",
    "    temp_x_train.append(list(np.array(x_train)[reshape_index]))\n",
    "\n",
    "for reshape_test_index in range(len(x_test)):\n",
    "    temp_x_test.append(list(np.array(x_test)[reshape_test_index]))\n",
    "    \n",
    "x_train = temp_x_train\n",
    "x_test = temp_x_test\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'D', 'Q', 'P'], dtype='<U1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dict = {\"K\":0, \"R\":1, \"H\":2, \"E\":3, \"D\":4, \"N\":5, \"Q\":6, \"T\":7, \"S\":8, \"C\":9, \"G\":10, \"A\":11, \"V\":12, \"L\":13, \"I\":14, \"M\":15, \"P\":16, \"Y\":17, \"F\":18, \"W\":19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_tensor = np.zeros(list(x_train.shape) + [20])    # shape: (batch_size, 4)\n",
    "x_test_tensor = np.zeros(list(x_test.shape) + [20])    # shape: (batch_size, 4)\n",
    "base_dict = {\"K\":0, \"R\":1, \"H\":2, \"E\":3, \"D\":4, \"N\":5, \"Q\":6, \"T\":7, \"S\":8, \"C\":9, \"G\":10, \"A\":11, \"V\":12, \"L\":13, \"I\":14, \"M\":15, \"P\":16, \"Y\":17, \"F\":18, \"W\":19}\n",
    "\n",
    "#base_dict = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "num_sample = len(x_train_tensor)\n",
    "seq_length = len(x_train[0])\n",
    "test_size = len(x_test)\n",
    "\n",
    "\n",
    "#naive one-hot encoding\n",
    "for row in range(num_sample):\n",
    "    for col in range(seq_length):\n",
    "        x_train_tensor[row,col,base_dict[x_train[row,col]]] = 1\n",
    "        if(row<test_size):\n",
    "            x_test_tensor[row,col,base_dict[x_test[row,col]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (16000, 4, 20)\n",
      "Training set label shape: (16000,)\n",
      "Test set shape: (4000, 4, 20)\n",
      "Test set label shape: (4000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape: {}'.format(x_train_tensor.shape))\n",
    "print('Training set label shape: {}'.format(y_train.shape))\n",
    "\n",
    "print('Test set shape: {}'.format(x_test_tensor.shape))\n",
    "print('Test set label shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REGG\n",
    "x_train_tensor[0][3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coefficient of determination (R^2) for regression\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "def kullback_leibler_divergence_ammar(y_true, y_pred):\n",
    "    tf.print(y_true,'tui')\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the entropy of a 1D tensor, fuzzing the edges with epsilon to keep numbers\n",
    "# clean.\n",
    "def calculate_entropy(y, epsilon):\n",
    "    clipped = tf.clip_by_value(y, epsilon, 1 - epsilon)\n",
    "    return -tf.cast(tf.reduce_sum(clipped * tf.log(clipped)), dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Sandbox for developing calculating the entropies of y\n",
    "def tf_entropies(y_true,y_pred, epsilon, nbins):\n",
    "    # Create histograms for the activations in the batch.\n",
    "    value_range = [0.0, 1.0]\n",
    "    # For prototype, only consider first two features.\n",
    "    neuron1 = y_true\n",
    "    neuron2 = y_pred\n",
    "    hist1 = tf.histogram_fixed_width(neuron1, value_range, nbins=nbins)\n",
    "    hist2 = tf.histogram_fixed_width(neuron2, value_range, nbins=nbins)\n",
    "    # Normalize\n",
    "    count = tf.cast(tf.count_nonzero(hist1), tf.int32)\n",
    "    dist1 = tf.divide(hist1, count)\n",
    "    dist2 = tf.divide(hist2, count)\n",
    "    neuron1_entropy = calculate_entropy(dist1, epsilon)\n",
    "    neuron2_entropy = calculate_entropy(dist2, epsilon)\n",
    "\n",
    "    # Calculate the joint distribution and then get the entropy\n",
    "    recast_n1 = tf.cast(tf.divide(tf.cast(nbins * neuron1, tf.int32), nbins), tf.float32)\n",
    "    meshed = recast_n1 + tf.divide(neuron2, nbins)  # Shift over the numbers for neuron2\n",
    "    joint_hist = tf.histogram_fixed_width(meshed, value_range, nbins=nbins * nbins)\n",
    "    joint_dist = tf.divide(joint_hist, count)\n",
    "    joint_entropy = calculate_entropy(joint_dist, epsilon)\n",
    "    \n",
    "    return neuron1_entropy+neuron2_entropy-joint_entropy\n",
    "\n",
    "def mi_loss(y_true,y_pred):\n",
    "    epsilon = 1e-5\n",
    "    bins = 10\n",
    "    return tf_entropies(y_true,y_pred,epsilon,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Flatten, Dropout \n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "#output_dim = nb_classes = 15 \n",
    "#input_dim = seq_length\n",
    "model = Sequential() \n",
    "model.add(Flatten())\n",
    "#model.add(Dense(100, activation='relu',input_shape=(41,4)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(41, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(4, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(20, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "#model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.add(Dense(1, activation='tanh'))\n",
    "\n",
    "#batch_size = 10000 \n",
    "#nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=mi_loss,optimizer=Adam(lr=0.0001), metrics=['mean_absolute_error'])\n",
    "#model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.0005), metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(x_train_flat, y_train, validation_split=0.2, epochs=25)  # starts training\n",
    "history = model.fit(x_train_tensor, y_train, validation_split=0.2, epochs=10)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np.array(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010038305\n",
      "0.015486715\n",
      "0.02112065\n",
      "0.025895352\n",
      "0.030217685\n",
      "0.034568083\n",
      "0.039084174\n",
      "0.04360605\n",
      "0.04826861\n",
      "0.05226369\n",
      "0.057357546\n",
      "0.06211581\n",
      "0.06749723\n",
      "0.07231683\n",
      "0.07731721\n",
      "0.082590625\n",
      "0.08964101\n",
      "0.09437617\n",
      "0.09917113\n",
      "0.10374277\n",
      "0.11014779\n",
      "0.115960695\n",
      "0.124943204\n",
      "0.12861207\n",
      "0.13437584\n",
      "0.14155488\n",
      "0.15007953\n",
      "0.15527305\n",
      "0.16314283\n",
      "0.17083804\n",
      "0.17947263\n",
      "0.1831211\n",
      "0.1925447\n",
      "0.20312814\n",
      "0.21044408\n",
      "0.21981914\n",
      "0.22754216\n",
      "0.2325908\n",
      "0.24532129\n",
      "0.25349155\n",
      "0.2663946\n",
      "0.27635098\n",
      "0.28358603\n",
      "0.29553455\n",
      "0.3036426\n",
      "0.31916204\n",
      "0.32378712\n",
      "0.3403353\n",
      "0.3464369\n",
      "0.36262766\n",
      "0.3737315\n",
      "0.3855045\n",
      "0.38936356\n",
      "0.41509742\n",
      "0.42418313\n",
      "0.4351038\n",
      "0.44813296\n",
      "0.46122888\n",
      "0.47669354\n",
      "0.4766736\n",
      "0.49176452\n",
      "0.50776297\n",
      "0.5203693\n",
      "0.53342956\n",
      "0.54186636\n",
      "0.565014\n",
      "0.5720714\n",
      "0.5836275\n",
      "0.59302104\n",
      "0.6102491\n",
      "0.60365164\n",
      "0.6244386\n",
      "0.6349219\n",
      "0.6382215\n",
      "0.6614192\n",
      "0.66639155\n",
      "0.68106705\n",
      "0.69431305\n",
      "0.7011089\n",
      "0.68938917\n",
      "0.69971013\n",
      "0.7167524\n",
      "0.7263703\n",
      "0.72393996\n",
      "0.73065317\n",
      "0.73961085\n",
      "0.75183934\n",
      "0.75610656\n",
      "0.7611116\n",
      "0.7599148\n",
      "0.7824743\n",
      "0.76723456\n",
      "0.7709466\n",
      "0.78439534\n",
      "0.7936012\n",
      "0.7864753\n",
      "0.80468583\n",
      "0.8112193\n",
      "0.8036526\n",
      "0.788542\n",
      "0.8201462\n",
      "0.82356197\n",
      "0.8261422\n",
      "0.81320155\n",
      "0.81777525\n",
      "0.8362856\n",
      "0.83847684\n",
      "0.84159625\n",
      "0.855478\n",
      "0.8567259\n",
      "0.8633161\n",
      "0.8505024\n",
      "0.8336118\n",
      "0.8397166\n",
      "0.8589431\n",
      "0.8410294\n",
      "0.85089725\n",
      "0.8432519\n",
      "0.8620596\n",
      "0.8459907\n",
      "0.8639098\n",
      "0.86050606\n",
      "0.85189354\n",
      "0.85824585\n",
      "0.8774966\n",
      "0.87671113\n",
      "0.86375\n",
      "0.8733375\n",
      "0.8689028\n",
      "0.86306673\n",
      "0.8730531\n",
      "0.8897285\n",
      "0.87704957\n",
      "0.8679128\n",
      "0.8722874\n",
      "0.8956832\n",
      "0.8792245\n",
      "0.87752324\n",
      "0.8767177\n",
      "0.8989753\n",
      "0.88298815\n",
      "0.88940275\n",
      "0.89817905\n",
      "0.8849735\n",
      "0.89648396\n",
      "0.8930553\n",
      "0.8830167\n",
      "0.8863742\n",
      "0.87936\n",
      "0.8991707\n",
      "0.88073313\n",
      "0.886239\n",
      "0.8679097\n",
      "0.89505893\n",
      "0.89946204\n",
      "0.871801\n",
      "0.872686\n",
      "0.9040137\n",
      "0.8854681\n",
      "0.89675397\n",
      "0.89237976\n",
      "0.8859521\n",
      "0.9073705\n",
      "0.8951229\n",
      "0.89445907\n",
      "0.9113646\n",
      "0.89028984\n",
      "0.8867384\n",
      "0.90957016\n",
      "0.8891644\n",
      "0.8917121\n",
      "0.9044791\n",
      "0.89044017\n",
      "0.92031527\n",
      "0.89950436\n",
      "0.90010935\n",
      "0.89457566\n",
      "0.89743847\n",
      "0.90592206\n",
      "0.91728115\n",
      "0.9130287\n",
      "0.9081757\n",
      "0.9103396\n",
      "0.88623965\n",
      "0.9075005\n",
      "0.91938484\n",
      "0.91458136\n",
      "0.9144644\n",
      "0.9040987\n",
      "0.8934846\n",
      "0.91346\n",
      "0.9127088\n",
      "0.93118733\n",
      "0.8965634\n",
      "0.9044038\n",
      "0.90298253\n",
      "0.90571946\n",
      "0.9075899\n",
      "0.91629463\n",
      "0.90616864\n",
      "0.9241656\n",
      "0.9116793\n",
      "0.91733205\n",
      "0.91321546\n",
      "0.92066956\n",
      "0.9251466\n",
      "0.9080398\n",
      "0.90842956\n",
      "0.9268468\n",
      "0.90595883\n",
      "0.9184073\n",
      "0.9310948\n",
      "0.9205643\n",
      "0.9059747\n",
      "0.90311015\n",
      "0.91239893\n",
      "0.92831075\n",
      "0.9140376\n",
      "0.9145883\n",
      "0.912251\n",
      "0.9201223\n",
      "0.927802\n",
      "0.91651064\n",
      "0.91761994\n",
      "0.91227233\n",
      "0.91858995\n",
      "0.9085255\n",
      "0.91680473\n",
      "0.92956245\n",
      "0.9077674\n",
      "0.9234051\n",
      "0.9210596\n",
      "0.9200652\n",
      "0.9384966\n",
      "0.9250696\n",
      "0.93695426\n",
      "0.92329574\n",
      "0.9255879\n",
      "0.90783656\n",
      "0.93372786\n",
      "0.9372542\n",
      "0.9105432\n",
      "0.91093326\n",
      "0.895644\n",
      "0.9184138\n",
      "0.91869384\n",
      "0.92774975\n",
      "0.93211395\n",
      "0.9255339\n",
      "0.92527974\n",
      "0.9211865\n",
      "0.92982864\n",
      "0.9292439\n",
      "0.92030257\n",
      "0.9416786\n",
      "0.9218552\n",
      "0.9326179\n",
      "0.92558926\n",
      "0.92596114\n",
      "0.93042266\n",
      "0.94375855\n",
      "0.91812557\n",
      "0.92540044\n",
      "0.9239018\n",
      "0.93074054\n",
      "0.9201068\n",
      "0.922194\n",
      "0.9282072\n",
      "0.9256564\n",
      "0.92554563\n",
      "0.92844796\n",
      "0.91949385\n",
      "0.9272214\n",
      "0.93831223\n",
      "0.93170536\n",
      "0.91444135\n",
      "0.93809587\n",
      "0.91993207\n",
      "0.92846036\n",
      "0.93644035\n",
      "0.9437974\n",
      "0.9255487\n",
      "0.9274116\n",
      "0.93785954\n",
      "0.930313\n",
      "0.93795174\n",
      "0.9381402\n",
      "0.9364775\n",
      "0.94157165\n",
      "0.9449741\n",
      "0.9315065\n",
      "0.91868865\n",
      "0.9458124\n",
      "0.923553\n",
      "0.93604\n",
      "0.9269077\n",
      "0.92783123\n",
      "0.91812354\n",
      "0.92663187\n",
      "0.92793375\n",
      "0.92674637\n",
      "0.9426362\n",
      "0.924211\n",
      "0.94057345\n",
      "0.95376724\n",
      "0.9444926\n",
      "0.9325247\n",
      "0.9258242\n",
      "0.94254434\n",
      "0.9381495\n",
      "0.92625797\n",
      "0.9287001\n",
      "0.9315461\n",
      "0.91735166\n",
      "0.9352939\n",
      "0.90156984\n",
      "0.94504327\n",
      "0.9448342\n",
      "0.92378587\n",
      "0.93774295\n",
      "0.9286956\n",
      "0.9235547\n",
      "0.945045\n",
      "0.9452658\n",
      "0.9143451\n",
      "0.9501233\n",
      "0.9372573\n",
      "0.94249725\n",
      "0.93627185\n",
      "0.9279936\n",
      "0.93061393\n",
      "0.9366402\n",
      "0.92215997\n",
      "0.9429203\n",
      "0.9374024\n",
      "0.9339635\n",
      "0.92772806\n",
      "0.93716717\n",
      "0.9262772\n",
      "0.93513846\n",
      "0.9283341\n",
      "0.951851\n",
      "0.933409\n",
      "0.9429974\n",
      "0.9485841\n",
      "0.941303\n",
      "0.9152476\n",
      "0.93934035\n",
      "0.9619588\n",
      "0.93240875\n",
      "0.93708736\n",
      "0.9460153\n",
      "0.9319919\n",
      "0.94596237\n",
      "0.9379032\n",
      "0.9152332\n",
      "0.91903675\n",
      "0.9379521\n",
      "0.93745196\n",
      "0.94811696\n",
      "0.9490911\n",
      "0.9446856\n",
      "0.9422228\n",
      "0.93145597\n",
      "0.93448424\n",
      "0.94080496\n",
      "0.9306421\n",
      "0.92895395\n",
      "0.9351295\n",
      "0.94010806\n",
      "0.9323152\n",
      "0.91949695\n",
      "0.94104224\n",
      "0.9496111\n",
      "0.9389991\n",
      "0.9450887\n",
      "0.94646245\n",
      "0.9410168\n",
      "0.9291486\n",
      "0.9315337\n",
      "0.93306434\n",
      "0.9396733\n",
      "0.9484761\n",
      "0.9272953\n",
      "0.93441474\n",
      "0.94555235\n",
      "0.92390454\n",
      "0.9457828\n",
      "0.9466035\n",
      "0.9336243\n",
      "0.93942356\n",
      "0.9314319\n",
      "0.92751753\n",
      "0.93100744\n",
      "0.93572253\n",
      "0.9445459\n",
      "0.94433814\n",
      "0.95150155\n",
      "0.96302027\n",
      "0.9738978\n",
      "0.9281429\n",
      "0.9391353\n",
      "0.9492053\n",
      "0.94487476\n",
      "0.93027824\n",
      "0.9484451\n",
      "0.96473116\n",
      "0.92187655\n",
      "0.94692546\n",
      "0.94366056\n",
      "0.94152105\n",
      "0.9414626\n",
      "0.9338809\n",
      "0.9452359\n",
      "0.95364106\n",
      "0.92925185\n",
      "0.9346156\n",
      "0.9407602\n",
      "0.9312915\n",
      "0.9350779\n",
      "0.9327699\n",
      "0.9474868\n",
      "0.93045914\n",
      "0.93245757\n",
      "0.9332164\n",
      "0.9277859\n",
      "0.93239707\n",
      "0.96148276\n",
      "0.95835334\n",
      "0.94612056\n",
      "0.9472804\n",
      "0.9494233\n",
      "0.94002\n",
      "0.9365432\n",
      "0.9539169\n",
      "0.93537647\n",
      "0.92938256\n",
      "0.94387585\n",
      "0.9318845\n",
      "0.93049765\n",
      "0.9447165\n",
      "0.9451582\n",
      "0.9633498\n",
      "0.9311588\n",
      "0.95021236\n",
      "0.92625177\n",
      "0.9609778\n",
      "0.9448527\n",
      "0.9251875\n",
      "0.9216124\n",
      "0.9429079\n",
      "0.9416057\n",
      "0.9508088\n",
      "0.9516756\n",
      "0.944162\n",
      "0.9284545\n",
      "0.9494681\n",
      "0.9640763\n",
      "0.9360699\n",
      "0.9268695\n",
      "0.9474882\n",
      "0.9357005\n",
      "0.9348461\n",
      "0.95789725\n",
      "0.94814587\n",
      "0.9475439\n",
      "0.94746476\n",
      "0.9350786\n",
      "0.9308554\n",
      "0.94858885\n",
      "0.96134037\n",
      "0.93982464\n",
      "0.94743246\n",
      "0.9474366\n",
      "0.9305541\n",
      "0.94128716\n",
      "0.94448745\n",
      "0.94197714\n",
      "0.95937216\n",
      "0.94242775\n",
      "0.9417756\n",
      "0.9329942\n",
      "0.95679104\n",
      "0.93118423\n",
      "0.9455269\n",
      "0.9199971\n",
      "0.94565624\n",
      "0.9407155\n",
      "0.95624346\n",
      "0.94527715\n",
      "0.958707\n",
      "0.94463533\n",
      "0.93642557\n",
      "0.93782413\n",
      "0.9462499\n",
      "0.9547555\n",
      "0.95502514\n",
      "0.94695437\n",
      "0.93479586\n",
      "0.94020367\n",
      "0.93350667\n",
      "0.94095075\n",
      "0.94840384\n",
      "0.96118766\n",
      "0.9203865\n",
      "0.9635899\n",
      "0.9358188\n",
      "0.93379766\n",
      "0.92594427\n",
      "0.93416363\n",
      "0.94764984\n",
      "0.9600759\n",
      "0.9421636\n",
      "0.92615134\n",
      "0.96418357\n",
      "0.9437548\n",
      "0.9489934\n",
      "0.9492238\n",
      "0.94125897\n",
      "0.92771226\n",
      "0.9480062\n",
      "0.95079917\n",
      "0.9372504\n",
      "0.91706514\n",
      "0.9456287\n",
      "0.9582777\n",
      "0.96134657\n",
      "0.94752944\n",
      "0.95030046\n",
      "0.94091433\n",
      "0.9353895\n",
      "0.9677835\n",
      "0.9371637\n",
      "0.94291687\n",
      "0.93394077\n",
      "0.92991984\n",
      "0.94858885\n",
      "0.9390253\n",
      "0.9220781\n",
      "0.93606234\n",
      "0.93229455\n",
      "0.9551001\n",
      "0.92744464\n",
      "0.93575966\n",
      "0.94754803\n",
      "0.9514376\n",
      "0.95130205\n",
      "0.9317862\n",
      "0.93950886\n",
      "0.9415548\n",
      "0.9364861\n",
      "0.95112664\n",
      "0.9370248\n",
      "0.9362928\n",
      "0.94240165\n",
      "0.9486597\n",
      "0.9444042\n",
      "0.93672895\n",
      "0.946739\n",
      "0.9338334\n",
      "0.9453838\n",
      "0.9465863\n",
      "0.9556271\n",
      "0.95446175\n",
      "0.95414394\n",
      "0.9345654\n",
      "0.9417323\n",
      "0.96623087\n",
      "0.9340715\n",
      "0.9341024\n",
      "0.92914796\n",
      "0.935783\n",
      "0.9382782\n",
      "0.9282791\n",
      "0.9328662\n",
      "0.9355973\n",
      "0.93520653\n",
      "0.9398907\n",
      "0.94667023\n",
      "0.9549261\n",
      "0.9355512\n",
      "0.9300017\n",
      "0.94260734\n",
      "0.9443347\n",
      "0.9502358\n",
      "0.95970374\n",
      "0.9440705\n",
      "0.9467425\n",
      "0.9507944\n",
      "0.9347381\n",
      "0.9471174\n",
      "0.9425874\n",
      "0.9366519\n",
      "0.9474868\n",
      "0.9462382\n",
      "0.94969094\n",
      "0.9326213\n",
      "0.95006794\n",
      "0.94208723\n",
      "0.9352334\n",
      "0.9489789\n",
      "0.93442506\n",
      "0.9425344\n",
      "0.9306738\n",
      "0.9485937\n",
      "0.9401521\n",
      "0.95571375\n",
      "0.95163983\n",
      "0.9450784\n",
      "0.9525933\n",
      "0.9450722\n",
      "0.9541673\n",
      "0.93754965\n",
      "0.945637\n",
      "0.9419786\n",
      "0.93993676\n",
      "0.9488427\n",
      "0.9519047\n",
      "0.94240505\n",
      "0.93486327\n",
      "0.92899865\n",
      "0.9447523\n",
      "0.9314787\n",
      "0.9597595\n",
      "0.934972\n",
      "0.9508797\n",
      "0.94791746\n",
      "0.9495176\n",
      "0.94055456\n",
      "0.9457959\n",
      "0.942985\n",
      "0.9527887\n",
      "0.95622146\n",
      "0.9540593\n",
      "0.9434163\n",
      "0.9459362\n",
      "0.9332755\n",
      "0.9364531\n",
      "0.94959736\n",
      "0.94148463\n",
      "0.930228\n",
      "0.9241866\n",
      "0.94524896\n",
      "0.96303815\n",
      "0.9323757\n",
      "0.9567959\n",
      "0.9511548\n",
      "0.9569108\n",
      "0.9631001\n",
      "0.961491\n",
      "0.9402835\n",
      "0.93634164\n",
      "0.9298373\n",
      "0.94447297\n",
      "0.94415104\n",
      "0.9320125\n",
      "0.9556622\n",
      "0.9499104\n",
      "0.9608863\n",
      "0.9471559\n",
      "0.94351745\n",
      "0.93883055\n",
      "0.94158506\n",
      "0.94216084\n",
      "0.94247246\n",
      "0.9465698\n",
      "0.95922637\n",
      "0.94035023\n",
      "0.9378668\n",
      "0.9592449\n",
      "0.92863065\n",
      "0.94214845\n",
      "0.95351654\n",
      "0.9591431\n",
      "0.9466558\n",
      "0.955279\n",
      "0.9311237\n",
      "0.949521\n",
      "0.95134264\n",
      "0.92699885\n",
      "0.9517857\n",
      "0.9429788\n",
      "0.9382692\n",
      "0.9628256\n",
      "0.9248835\n",
      "0.9513619\n",
      "0.9578966\n",
      "0.95394164\n",
      "0.9340405\n",
      "0.94528955\n",
      "0.9342042\n",
      "0.9763345\n",
      "0.9329942\n",
      "0.9442769\n",
      "0.94246906\n",
      "0.9386813\n",
      "0.9466407\n",
      "0.93647236\n",
      "0.96333605\n",
      "0.9228747\n",
      "0.9467411\n",
      "0.9242781\n",
      "0.95063615\n",
      "0.94209963\n",
      "0.9431432\n",
      "0.9461825\n",
      "0.9518916\n",
      "0.9440073\n",
      "0.93775123\n",
      "0.9416841\n",
      "0.94448054\n",
      "0.95578533\n",
      "0.9552123\n",
      "0.95671886\n",
      "0.94965583\n",
      "0.9490752\n",
      "0.9484719\n",
      "0.96491486\n",
      "0.9571825\n",
      "0.9616238\n",
      "0.93686104\n",
      "0.9354308\n",
      "0.9333959\n",
      "0.9539444\n",
      "0.94397146\n",
      "0.9477592\n",
      "0.9558231\n",
      "0.9424546\n",
      "0.95285475\n",
      "0.94121426\n",
      "0.9652327\n",
      "0.95036924\n",
      "0.93887115\n",
      "0.9565056\n",
      "0.9600601\n",
      "0.9524812\n",
      "0.95359355\n",
      "0.9234725\n",
      "0.94969165\n",
      "0.94480455\n",
      "0.96055543\n",
      "0.9129527\n",
      "0.94169444\n",
      "0.9474799\n",
      "0.9356668\n",
      "0.95166737\n",
      "0.9370062\n",
      "0.93697387\n",
      "0.9524028\n",
      "0.9356159\n",
      "0.95392174\n",
      "0.94396114\n",
      "0.9418829\n",
      "0.945692\n",
      "0.9631008\n",
      "0.95804447\n",
      "0.9605018\n",
      "0.94685805\n",
      "0.9464577\n",
      "0.9488957\n",
      "0.95940316\n",
      "0.948\n",
      "0.9463758\n",
      "0.9333182\n",
      "0.9435374\n",
      "0.9481658\n",
      "0.9402553\n",
      "0.93977374\n",
      "0.9684618\n",
      "0.9337392\n",
      "0.9282048\n",
      "0.9475336\n",
      "0.95661426\n",
      "0.9727146\n",
      "0.9564767\n",
      "0.9333932\n",
      "0.9401885\n",
      "0.95902824\n",
      "0.9416752\n",
      "0.93817705\n",
      "0.9362061\n",
      "0.94995785\n",
      "0.95513314\n",
      "0.9343549\n",
      "0.9315296\n",
      "0.9509526\n",
      "0.94290036\n",
      "0.94700867\n",
      "0.9430139\n",
      "0.9399375\n",
      "0.94621825\n",
      "0.96786535\n",
      "0.94527715\n",
      "0.94099617\n",
      "0.9604976\n",
      "0.94053733\n",
      "0.9516454\n",
      "0.94993514\n",
      "0.96191067\n",
      "0.96783096\n",
      "0.9509306\n",
      "0.9516825\n",
      "0.9407141\n",
      "0.94289076\n",
      "0.9504807\n",
      "0.95784014\n",
      "0.9431831\n",
      "0.94378436\n",
      "0.9619843\n",
      "0.9433799\n",
      "0.952118\n",
      "0.9461151\n",
      "0.95744944\n",
      "0.9578154\n",
      "0.9429011\n",
      "0.92938805\n",
      "0.9417914\n",
      "0.9206995\n",
      "0.96383137\n",
      "0.95189506\n",
      "0.95161027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9400049\n",
      "0.95673394\n",
      "0.96230555\n",
      "0.9390294\n",
      "0.95182353\n",
      "0.9465684\n",
      "0.9414227\n",
      "0.93292123\n",
      "0.9768408\n",
      "0.9357858\n",
      "0.9507765\n",
      "0.9449394\n",
      "0.94817406\n",
      "0.950676\n",
      "0.9485744\n",
      "0.93729514\n",
      "0.95218676\n",
      "0.94648176\n",
      "0.9486432\n",
      "0.9451884\n",
      "0.9626846\n",
      "0.9539919\n",
      "0.95896834\n",
      "0.9463586\n",
      "0.97061366\n",
      "0.93975925\n",
      "0.95292974\n",
      "0.9411234\n",
      "0.9452455\n",
      "0.9424649\n",
      "0.9263914\n",
      "0.96902245\n",
      "0.94083244\n",
      "0.9552061\n",
      "0.9467067\n",
      "0.9518194\n",
      "0.9515394\n",
      "0.9396843\n",
      "0.9443333\n",
      "0.9363568\n",
      "0.9440609\n",
      "0.9496806\n",
      "0.9516426\n",
      "0.9431494\n",
      "0.9475632\n",
      "0.939297\n",
      "0.9552563\n",
      "0.94046855\n",
      "0.9374183\n",
      "0.9512849\n",
      "0.9329336\n",
      "0.94762236\n",
      "0.9386765\n",
      "0.96770304\n",
      "0.95228374\n",
      "0.9505254\n",
      "0.9429726\n",
      "0.95675665\n",
      "0.9419682\n",
      "0.94565207\n",
      "0.9248037\n",
      "0.95021445\n",
      "0.9409219\n",
      "0.9533253\n",
      "0.9590881\n",
      "0.94018716\n",
      "0.95649385\n",
      "0.94361925\n",
      "0.9435243\n",
      "0.9511363\n",
      "0.9283988\n",
      "0.9396265\n",
      "0.9302328\n",
      "0.9502826\n",
      "0.96832424\n",
      "0.9434143\n",
      "0.93538886\n",
      "0.94038737\n",
      "0.95782846\n",
      "0.9512931\n",
      "0.93101704\n",
      "0.9378537\n",
      "0.9386668\n",
      "0.94628567\n",
      "0.96800023\n",
      "0.9541487\n",
      "0.95646703\n",
      "0.94107527\n",
      "0.9207593\n",
      "0.93499947\n",
      "0.95040846\n",
      "0.9529923\n",
      "0.9503087\n",
      "0.9478115\n",
      "0.9452132\n",
      "0.94959736\n",
      "0.9663939\n",
      "0.93762535\n",
      "0.9468732\n",
      "0.9571474\n",
      "0.9672394\n",
      "0.9509691\n",
      "0.94519806\n",
      "0.9298758\n",
      "0.9401232\n",
      "0.917588\n",
      "0.9455771\n",
      "0.9497535\n",
      "0.94650376\n",
      "0.93929976\n",
      "0.946761\n",
      "0.93896264\n",
      "0.9390885\n",
      "0.94996196\n",
      "0.9713071\n",
      "0.96961546\n",
      "0.93504214\n",
      "0.9331235\n",
      "0.9519859\n",
      "0.95672643\n",
      "0.96011174\n",
      "0.95355505\n",
      "0.9379411\n",
      "0.94103676\n",
      "0.956972\n",
      "0.9628359\n",
      "0.9498836\n",
      "0.96302855\n",
      "0.93287516\n",
      "0.9485531\n",
      "0.96532345\n",
      "0.94720477\n",
      "0.9275767\n",
      "0.94673836\n",
      "0.9423452\n",
      "0.9321473\n",
      "0.9598173\n",
      "0.9489204\n",
      "0.9500831\n",
      "0.9355347\n",
      "0.950793\n",
      "0.9542643\n",
      "0.92938185\n",
      "0.95152223\n",
      "0.94326293\n",
      "0.94645077\n",
      "0.9483192\n",
      "0.94775236\n",
      "0.94047266\n",
      "0.94119364\n",
      "0.9311044\n",
      "0.9458908\n",
      "0.95553833\n",
      "0.9508893\n",
      "0.954955\n",
      "0.96368206\n",
      "0.94438285\n",
      "0.94335645\n",
      "0.9372532\n",
      "0.9227213\n",
      "0.9489287\n",
      "0.96655625\n",
      "0.95085764\n",
      "0.94689107\n",
      "0.9419283\n",
      "0.94050705\n",
      "0.9529737\n",
      "0.9559621\n",
      "0.92694795\n",
      "0.96118075\n",
      "0.947989\n",
      "0.9516928\n",
      "0.9597911\n",
      "0.94120735\n",
      "0.94654846\n",
      "0.9269218\n",
      "0.9363877\n",
      "0.93424964\n",
      "0.9450804\n",
      "Exact mutual information:  0.9492876779618222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "n_hidden = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(stddev=0.1, shape=[1, n_hidden]))\n",
    "Wy = tf.Variable(tf.random_normal(stddev=0.1, shape=[1, n_hidden]))\n",
    "b = tf.Variable(tf.constant(0.1, shape=[n_hidden]))\n",
    "\n",
    "hidden_joint = tf.nn.relu(tf.matmul(x, Wx) + tf.matmul(y, Wy) + b)\n",
    "hidden_marg = tf.nn.relu(tf.matmul(x, Wx) + tf.matmul(y_, Wy) + b)\n",
    "\n",
    "Wout = tf.Variable(tf.random_normal(stddev=0.1, shape=[n_hidden, 1]))\n",
    "bout = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "out_joint = tf.matmul(hidden_joint, Wout) + bout\n",
    "out_marg = tf.matmul(hidden_marg, Wout) + bout\n",
    "\n",
    "# Dont forget the change-of-base formula at the end to go from log base 10 to log base 2\n",
    "lower_bound = (tf.reduce_mean(out_joint) - tf.log(tf.reduce_mean(tf.exp(out_marg)))) / tf.log(tf.constant(2, dtype=tf.float32))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.005).minimize(-lower_bound)\n",
    "\n",
    "# Now demonstrate in example\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    sig2 = 0.2 # 1.0\n",
    "    N = 20000\n",
    "    for i in range(1000):\n",
    "        x_sample = np.sign(np.random.normal(0., 1., [N, 1])) # np.random.normal(0.,1.,[N,1])\n",
    "        y_sample = x_sample+np.random.normal(0., np.sqrt(sig2), [N, 1])\n",
    "        y_shuffle = np.random.permutation(y_sample)\n",
    "        _, loss_value = sess.run((train_step, lower_bound), feed_dict={x: x_sample, y: y_sample, y_: y_shuffle})\n",
    "        # Print out the MINE-calculated loss during every iteration.\n",
    "        print(loss_value)\n",
    "\n",
    "# This code calculates the exact MI by hand\n",
    "N = 100000\n",
    "sig2 = 0.2 # -> sig2=0.2 should lead to MI=0.95\n",
    "x = np.sign(np.random.normal(0., 1., [N, 1]))\n",
    "y = x + np.random.normal(0., np.sqrt(sig2),[N,1])\n",
    "\n",
    "p_y_x = np.exp(-(y - x)**2 / (2 * sig2))\n",
    "p_y_x_minus = np.exp(-(y + 1)**2 / (2 * sig2))\n",
    "p_y_x_plus = np.exp(-(y - 1)**2 / (2 * sig2))\n",
    "mi = np.average(np.log2(p_y_x / (0.5 * p_y_x_minus + 0.5 * p_y_x_plus)))\n",
    "print(\"Exact mutual information: \", mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "motif_learn_convnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
